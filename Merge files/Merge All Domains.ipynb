{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a2f4a8c",
   "metadata": {},
   "source": [
    "# Merging Data Across Domains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0d186a",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- Clean and Combine more worksheets for Economic Vitality\n",
    "- Clean and Combine more worksheets for Environment and Natural Resources\n",
    "- Add in missing percentages (if time)\n",
    "- Add moes (if time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4adac752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fbb5eb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Health and Nutrition\n",
    "health = pd.read_csv(\"/data/discover/Data/Output/health_and_nutrition_measures_final_output.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'geo_name':str}, low_memory=False)\n",
    "\n",
    "# Create tribal_fips variable to match the safety dataframe\n",
    "health.loc[health[\"area_type\"] == \"tribal area\", \"tribal_fips\"] = health[\"GEO_ID\"] \n",
    "\n",
    "#Drop block data\n",
    "health_filtered = health[~health.area_type.str.contains(\"block_group\")]\n",
    "\n",
    "#Drop MOE variables\n",
    "health_filtered=health_filtered.drop(columns=['Percent_with_disability_moe','Percent_with_food_stamps_moe',\n",
    "                                               'Fertility_rate_moe',\"Percent_private_health_insurance_moe\",\n",
    "                                               \"Percent_public_coverage_moe\",'Percent_with_hearing_difficulty_moe',\n",
    "                                               'Percent_with_vision_difficulty_moe','Percent_with_cognitive_difficulty_moe',\n",
    "                                              \"Percent_with_ambulatory_difficulty_moe\",\"Percent_with_selfcare_difficulty_moe\",\n",
    "                                              \"Percent_with_independent_living_difficulty_moe\", \"blockgroup_fips\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "health_filtered.columns=map(str.upper, health_filtered.columns)\n",
    "\n",
    "#Save in health folder\n",
    "health_filtered.to_csv(\"/data/discover/Data/Final Data/Health and Nutrition/health_and_nutrition.csv\", header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2880c11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Infrastructure, Housing, and Transportation\n",
    "house = pd.read_csv(\"/data/discover/Data/Output/Housing_trans_infra_measures.csv\", \n",
    "                    dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'geo_name':str}, low_memory=False)\n",
    "\n",
    "# Create tribal_fips variable to match the safety dataframe\n",
    "house.loc[house[\"area_type\"] == \"tribal area\", \"tribal_fips\"] = house[\"GEO_ID\"] \n",
    "\n",
    "#Drop MOEs\n",
    "house=house.drop(columns=['Total_housing_units_moe','Median_home_value_moe',\n",
    "                                               'Median_gross_rent_moe',\"Percent_drove_alone_moe\",\n",
    "                                               \"Percent_carpooled_moe\",\"Percent_public_transportation_moe\",\n",
    "                                               \"Percent_walked_moe\",\"Average_commute_time_moe\",\n",
    "                                              \"Percent_with_1.00_occupent_or_less_moe\",\n",
    "                                              \"Percent_with_1.01_to_1.50_occupents_moe\",\n",
    "                                              \"Percent_with_1.51_or_more_occupents_moe\", \"Percent_with_utility_gas_moe\",\n",
    "                                              \"Percent_with_bottled_tank_lp_gas_moe\", \"Percent_with_electricity_moe\",\n",
    "                                              \"Percent_with_oil_kerosene_etc_moe\", \"Percent_with_solar_moe\",\n",
    "                                              \"Percent_with_no_fuel_moe\", \"Number_employed_construction_moe\",\n",
    "                                              \"Percent_vacant_moe\", \"Percent_with_broadband_cable_fiber_esl_moe\",\n",
    "                                              \"Percent_with_cellular_data_plan_moe\", \"Percent_with_satellite_internet_moe\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "house.columns=map(str.upper, house.columns)\n",
    "\n",
    "#Save in house folder\n",
    "house.to_csv(\"/data/discover/Data/Final Data/Infrastructure Housing and Transportation/house_trans_infra.csv\", \n",
    "             header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a0ce980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Income, Poverty, and Social Services\n",
    "income = pd.read_csv(\"/data/create/data/inc_pov_ss_measures.csv\", dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'geo_name':str}, low_memory=False)\n",
    "\n",
    "# Create tribal_fips variable\n",
    "income.loc[income[\"area_type\"] == \"tribal area\", \"tribal_fips\"] = income[\"GEO_ID\"] \n",
    "\n",
    "# Make all column names uppercase\n",
    "income.columns=map(str.upper, income.columns)\n",
    "\n",
    "#Save in income folder\n",
    "income.to_csv(\"/data/discover/Data/Final Data/Income Poverty and Social Services/inc_pov_ss.csv\", \n",
    "             header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a16df188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Education\n",
    "education = pd.read_csv(\"/data/create/data/Education.csv\", dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'geo_name':str}, low_memory=False)\n",
    "\n",
    "#drop variables\n",
    "education = education.drop(['blockgroup_fips'], axis=1)\n",
    "\n",
    "# Make all column names uppercase\n",
    "education.columns=map(str.upper, education.columns)\n",
    "\n",
    "#Rename columns with ' in the name\n",
    "education.rename(columns = {\"EDA_ASSOCIATE'S\":\"EDA_ASSOCIATES\"}, inplace = True)\n",
    "education.rename(columns = {\"EDA_BACHELOR'S\":\"EDA_BACHELORS\"}, inplace = True)\n",
    "\n",
    "#Save in income folder\n",
    "education.to_csv(\"/data/discover/Data/Final Data/Education/education.csv\", \n",
    "             header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b45b4144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Public Safety; Disaster;\n",
    "safety_dis_gen = pd.read_csv(\"/data/engage/DSTP_merged_2015_2022_v2.csv\", \n",
    "                             dtype={'year':str,'state_fip': object,'county_fip':object,'tract_fip':object,'GEO_ID':str,\n",
    "                                    'area_type':str,'geo_name':str,\"division_fips\":str,\"region_fips\":str}, low_memory=False)\n",
    "\n",
    "# Rename fips variables\n",
    "safety_dis_gen.rename(columns = {'state_fip':'state_fips', 'county_fip':'county_fips', 'tribal_fip':'tribal_fips',\n",
    "                    'region_fip':'region_fips', 'division_fip':'division_fips', 'tract_fip':'tract_fips'}, inplace = True)\n",
    "\n",
    "# Assign GEO_ID value for nation, region, and division\n",
    "safety_dis_gen.loc[safety_dis_gen[\"area_type\"] == \"national\", \"GEO_ID\"] = \"us\"\n",
    "#safety_dis_gen.loc[safety_dis_gen[\"area_type\"] == \"division\", \"GEO_ID\"] = safety_dis_gen[\"division_fips\"] \n",
    "#safety_dis_gen.loc[safety_dis_gen[\"area_type\"] == \"region\", \"GEO_ID\"] = safety_dis_gen[\"region_fips\"] \n",
    "\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['Northeast Region']),\"GEO_ID\"] = \"1\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['South Region']),\"GEO_ID\"] = \"2\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['West Region']),\"GEO_ID\"] = \"3\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['Midwest Region']),\"GEO_ID\"] = \"4\"\n",
    "\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['New England Division']),\"GEO_ID\"] = \"1\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['Middle Atlantic Division']),\"GEO_ID\"] = \"2\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['East North Central Division']),\"GEO_ID\"] = \"3\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['West North Central Division']),\"GEO_ID\"] = \"4\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['South Atlantic Division']),\"GEO_ID\"] = \"5\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['East South Central Division']),\"GEO_ID\"] = \"6\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['West South Central Division']),\"GEO_ID\"] = \"7\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['Mountain Division']),\"GEO_ID\"] = \"8\"\n",
    "safety_dis_gen.loc[safety_dis_gen['geo_name'].isin(['Pacific Division']),\"GEO_ID\"] = \"9\"\n",
    "\n",
    "#drop variables\n",
    "safety_dis_gen = safety_dis_gen.drop(['region_fips','division_fips'], axis=1)\n",
    "\n",
    "#Seperate Public Safety\n",
    "safety=safety_dis_gen[[\"year\",\"area_type\",\"geo_name\",\"state_fips\",\"county_fips\",\"tract_fips\",\"tribal_fips\",\"GEO_ID\",\n",
    "                       \"Jud FTE\", \"Jud FTE Flag\", \"Jud FTE Payroll\", \"Jud FTE Payroll Flag\", \"Jud PTE\", \"Jud PTE Flag\", \n",
    "                       \"Jud PT Payroll\", \"Jud PT Payroll Flag\", \"Jud Indv Unit Id\", \"Jud Pop/Enroll/Function\", \"PO FTE\",\n",
    "                       \"PO FTE Flag\", \"PO FTE Payroll\", \"PO FTE Payroll Flag\", \"PO PTE\", \"PO PTE Flag\", \"PO PT Payroll\",\n",
    "                       \"PO PT Payroll Flag\", \"PO Indv Unit Id\", \"PO Pop/Enroll/Function\", \"Violent Crimes\", \n",
    "                       \"Violent Crime Rate per 100k\", \"Property Crimes\", \"Property Crime Rate per 100k\", \"judicialspending\",\n",
    "                       \"policespending\", \"totalincarcerated\"]]\n",
    "\n",
    "# Make all column names uppercase\n",
    "safety.columns=map(str.upper, safety.columns)\n",
    "\n",
    "#Save in safety folder\n",
    "safety.to_csv(\"/data/discover/Data/Final Data/Public Safety/safety.csv\", \n",
    "             header=True, index=False)\n",
    "\n",
    "#Seperate Disaster\n",
    "disaster=safety_dis_gen[[\"year\",\"area_type\",\"geo_name\",\"state_fips\",\"county_fips\",\"tract_fips\",\"tribal_fips\",\"GEO_ID\",\n",
    "                       \"AREA\", \"RISK_VALUE\", \"RISK_RATNG\", \"EAL_SCORE\", \"SOVI_SPCTL\", \"RESL_RATNG\", \"RESL_SPCTL\", \n",
    "                         \"CFLD_AFREQ\", \"CFLD_EXP_AREA\", \"ERQK_EXPT\", \"HWAV_EXPT\", \"HRCN_EXPT\", \"TRND_EXPT\", \"WFIR_EXPT\"]]\n",
    "\n",
    "disaster = disaster.assign(RESL_SPCTL = disaster.RESL_SPCTL.mul(100))\n",
    "disaster = disaster.assign(SOVI_SPCTL = disaster.SOVI_SPCTL.mul(100))\n",
    "\n",
    "# Make all column names uppercase\n",
    "disaster.columns=map(str.upper, disaster.columns)\n",
    "\n",
    "#Save in safety folder\n",
    "disaster.to_csv(\"/data/discover/Data/Final Data/Disaster Prevention/disaster.csv\", \n",
    "             header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e3ff8cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in General\n",
    "general1 = pd.read_csv(\"/data/discover/Data/General/general_measures.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'Geo_name':str}, low_memory=False)\n",
    "\n",
    "general2 = pd.read_csv(\"/data/discover/Data/General/general_measures2.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'Geo_name':str}, low_memory=False)\n",
    "\n",
    "general3 = pd.read_csv(\"/data/discover/Data/General/general_measures3.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'Geo_name':str}, low_memory=False)\n",
    "\n",
    "general4 = pd.read_csv(\"/data/discover/Data/General/general_measures4.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'Geo_name':str}, low_memory=False)\n",
    "\n",
    "merged_df = pd.merge(general1, general2, on=['Geo_name','GEO_ID','year','area_type','state_fips', 'county_fips', 'tract_fips'],\n",
    "                     how='outer').merge(general3, on=['Geo_name','GEO_ID','year','area_type','state_fips', 'county_fips', 'tract_fips'],\n",
    "                     how='outer').merge(general4, on=['Geo_name','GEO_ID','year','area_type','state_fips', 'county_fips', 'tract_fips'],\n",
    "                     how='outer')\n",
    "\n",
    "# Create tribal_fips variable to match the safety dataframe\n",
    "merged_df.loc[merged_df[\"area_type\"] == \"tribal area\", \"tribal_fips\"] = merged_df[\"GEO_ID\"] \n",
    "\n",
    "#Drop MOE variables\n",
    "merged_df=merged_df.drop(columns=['Total_population_moe', \"Median_age_moe\",\n",
    "                 \"Percent_non_Hispanic_White_alone_moe\", \"Percent_non_Hispanic_Black_alone_moe\",\n",
    "                 \"Percent_non_Hispanic_AIAN_alone_moe\", \"Percent_non_Hispanic_Asian_alone_moe\",\n",
    "                 \"Percent_non_Hispanic_NHPI_alone_moe\", \"Percent_non_Hispanic_SOR_alone_moe\",\n",
    "                 \"Percent_non_Hispanic_Multi_alone_moe\", \"Percent_Hispanic_moe\",\n",
    "                 \"Percent_bachelors_degree_or_higher_moe\", \"Percent_high_school_graduate_or_higher_moe\",\n",
    "                 \"Median_household_income_moe\",\"Poverty_rate_moe\",\n",
    "                 \"Percent_employed_moe\", \"Percent_unemployed_moe\",\n",
    "                 \"Percent_speak_English_less_than_very_well_moe\", \"Percent_civilian_veteran_moe\",\n",
    "                 \"Percent_no_health_insurance_moe\",'Total_households_moe', \"Married_coupled__moe\",\n",
    "                 \"Cohab_coupled_households_moe\",\"Male_hh_nospousepartner_moe\", \"Female_hh_nospousepartner_moe\",\n",
    "                 \"Avg_hh_size_moe\", \"Percent_foreign_born_moe\", \"Percent_morgage_gt_35%_inc_moe\",\n",
    "                 \"Percent_under_5_moe\", \"Percent_5_to_9_moe\",\"Percent_10_to_14_moe\", \"Percent_15_to_19_moe\",\n",
    "                  \"Percent_20_to_24_moe\", \"Percent_25_to_29_moe\",\"Percent_30_to_34_moe\", \"Percent_35_to_39_moe\",\n",
    "                 \"Percent_40_to_44_moe\", \"Percent_45_to_49_moe\", \"Percent_50_to_54_moe\", \"Percent_55_to_59_moe\",\n",
    "                  \"Percent_60_to_64_moe\", \"Percent_65_to_69_moe\", \"Percent_70_to_74_moe\", \"Percent_75_to_79_moe\",\n",
    "                  \"Percent_80_to_84_moe\", \"Percent_85_and_over_moe\",\"Median_age_male_moe\", \"Median_age_female_moe\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "merged_df.columns=map(str.upper, merged_df.columns)\n",
    "\n",
    "#Save in general folder\n",
    "merged_df.to_csv(\"/data/discover/Data/Final Data/General/general.csv\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ca8a662",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine general and heatlh (outer merge)\n",
    "gen_hlth = merged_df.merge(health_filtered,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE','STATE_FIPS', 'COUNTY_FIPS', 'TRACT_FIPS','TRIBAL_FIPS'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y\n",
    "gen_hlth.rename(columns = {'GEO_NAME_x':'GEO_NAME'}, inplace = True)\n",
    "gen_hlth = gen_hlth.drop(['GEO_NAME_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62aa7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine house (outer merge)\n",
    "gen_hlth_house = gen_hlth.merge(house,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE','STATE_FIPS', 'COUNTY_FIPS', 'TRACT_FIPS','TRIBAL_FIPS'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y\n",
    "gen_hlth_house.rename(columns = {'GEO_NAME_x':'GEO_NAME'}, inplace = True)\n",
    "gen_hlth_house = gen_hlth_house.drop(['GEO_NAME_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "159969c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine income (outer merge)\n",
    "gen_hlth_house_inc = gen_hlth_house.merge(income,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE','STATE_FIPS', 'COUNTY_FIPS', 'TRACT_FIPS','TRIBAL_FIPS'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y\n",
    "gen_hlth_house_inc.rename(columns = {'GEO_NAME_x':'GEO_NAME'}, inplace = True)\n",
    "gen_hlth_house_inc = gen_hlth_house_inc.drop(['GEO_NAME_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08468cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine education (outer merge)\n",
    "gen_hlth_house_inc_ed = gen_hlth_house_inc.merge(education,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE', 'STATE_FIPS', 'COUNTY_FIPS', 'TRACT_FIPS'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y\n",
    "gen_hlth_house_inc_ed.rename(columns = {'GEO_NAME_x':'GEO_NAME'}, inplace = True)\n",
    "gen_hlth_house_inc_ed = gen_hlth_house_inc_ed.drop(['GEO_NAME_y'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e50ac517",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine Safety dfs (outer merge)\n",
    "gen_hlth_house_inc_ed_safe = gen_hlth_house_inc_ed.merge(safety,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y and STATE_FIPS (safety dataframe had different state_fips for tribal areas)\n",
    "gen_hlth_house_inc_ed_safe.rename(columns = {'GEO_NAME_x':'GEO_NAME', 'STATE_FIPS_x':'STATE_FIPS', 'COUNTY_FIPS_x':'COUNTY_FIPS', 'TRACT_FIPS_x':'TRACT_FIPS', 'TRIBAL_FIPS_x':'TRIBAL_FIPS'}, inplace = True)\n",
    "gen_hlth_house_inc_ed_safe = gen_hlth_house_inc_ed_safe.drop(['GEO_NAME_y','STATE_FIPS_y', 'COUNTY_FIPS_y', 'TRACT_FIPS_y', 'TRIBAL_FIPS_y' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f90792a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine disaster dfs (outer merge)\n",
    "gen_hlth_house_inc_ed_safe_dis = gen_hlth_house_inc_ed_safe.merge(disaster,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                                how='outer')\n",
    "\n",
    "#rename and drop GEO_NAME_x and GEO_NAME_y and STATE_FIPS (safety dataframe had different state_fips for tribal areas)\n",
    "gen_hlth_house_inc_ed_safe_dis.rename(columns = {'GEO_NAME_x':'GEO_NAME', 'STATE_FIPS_x':'STATE_FIPS', 'COUNTY_FIPS_x':'COUNTY_FIPS', 'TRACT_FIPS_x':'TRACT_FIPS', 'TRIBAL_FIPS_x':'TRIBAL_FIPS'}, inplace = True)\n",
    "gen_hlth_house_inc_ed_safe_dis = gen_hlth_house_inc_ed_safe_dis.drop(['GEO_NAME_y','STATE_FIPS_y', 'COUNTY_FIPS_y', 'TRACT_FIPS_y', 'TRIBAL_FIPS_y' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f181d20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Environment and Natural Resources\n",
    "environment = pd.read_csv(\"/data/discover/Data/Final Data/Environment and Natural Resources/environment.csv\",\n",
    "                         dtype={'YEAR':str,'GEO_ID':str, 'AREA_TYPE':str, 'STATE_FIPS': object,'COUNTY_FIPS':object,})\n",
    "\n",
    "#Combine environment df (outer merge)\n",
    "gen_hlth_hse_inc_ed_safe_dis_env = gen_hlth_house_inc_ed_safe_dis.merge(environment,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE','GEO_NAME','STATE_FIPS', 'COUNTY_FIPS'],\n",
    "                                how='outer')\n",
    "\n",
    "#Remove geographies that no longer exist\n",
    "gen_hlth_hse_inc_ed_safe_dis_env = gen_hlth_hse_inc_ed_safe_dis_env[~gen_hlth_hse_inc_ed_safe_dis_env.GEO_NAME.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "755e94d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Economic Vitality\n",
    "economic = pd.read_csv(\"/data/discover/Data/Final Data/Economic Vitality/economic.csv\",\n",
    "                         dtype={'YEAR':str,'GEO_ID':str, 'AREA_TYPE':str, 'STATE_FIPS': object})\n",
    "\n",
    "#Combine environment df (outer merge)\n",
    "gen_hlth_hse_inc_ed_safe_dis_env_ec = gen_hlth_hse_inc_ed_safe_dis_env.merge(economic,\n",
    "                                on=['GEO_ID','YEAR','AREA_TYPE','GEO_NAME','STATE_FIPS'],\n",
    "                                how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8aec2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unwanted columns\n",
    "gen_hlth_hse_inc_ed_safe_dis_env_ec = gen_hlth_hse_inc_ed_safe_dis_env_ec.drop(['BLOCKGROUP_FIP', 'UNNAMED: 0'], axis=1)\n",
    "\n",
    "#Drop duplicated columns and columns that aren't applicable\n",
    "gen_hlth_hse_inc_ed_safe_dis_env_ec = gen_hlth_hse_inc_ed_safe_dis_env_ec.drop(['MED_HH_INC','PCT_HH_FOODSTAMP',\n",
    "                                                                                'PCT_BELOW_POV', 'EST_HH_CHILDREN_SSI_CASHPAI_FOODSTAMP',\n",
    "                                                                               'EST_HH_CHILDREN_NO_SSI_CASHPAI_FOODSTAMP',\n",
    "                                                                               'JUD FTE FLAG', 'JUD FTE PAYROLL FLAG', 'JUD PTE FLAG',\n",
    "                                                                                'JUD PT PAYROLL FLAG', 'JUD INDV UNIT ID', 'JUD POP/ENROLL/FUNCTION',\n",
    "                                                                                'PO FTE FLAG', 'PO FTE PAYROLL FLAG', 'PO PTE FLAG', \n",
    "                                                                                'PO PT PAYROLL FLAG', 'PO INDV UNIT ID', 'PO POP/ENROLL/FUNCTION',\n",
    "                                                                                'WITH_INTERNET', \"WITHOUT_INTERNET\"], axis=1)\n",
    "\n",
    "#drop duplicated tribal areas\n",
    "merge = gen_hlth_hse_inc_ed_safe_dis_env_ec.drop_duplicates()\n",
    "\n",
    "#Changing GEO_ID for region and division\n",
    "merge.loc[(merge[\"AREA_TYPE\"] == 'region'), \"GEO_ID\"] = 'R' + merge[\"GEO_ID\"]\n",
    "merge.loc[(merge[\"AREA_TYPE\"] == 'division'), \"GEO_ID\"] = 'D' + merge[\"GEO_ID\"]\n",
    "\n",
    "#Removing semicolon from tracts in 2022\n",
    "merge.loc[(merge['YEAR'] == '2022') & (merge['AREA_TYPE'] == 'tract'), 'GEO_NAME'] = merge.loc[(merge['YEAR'] == '2022') \n",
    "                                            & (merge['AREA_TYPE'] == 'tract'), 'GEO_NAME'].str.replace(';', ',')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b8fdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in merge folder\n",
    "merge.to_csv(\"/data/discover/Data/Final Data/Merged/merged_data.csv\", \n",
    "             header=True, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

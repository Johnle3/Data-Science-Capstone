{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8a2cd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112f0dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dict= {\"GEO_NAME\":str,\n",
    "             \"GEO_ID\":str,\n",
    "             \"YEAR\":str,\n",
    "             \"AREA_TYPE\":str,\n",
    "             \"STATE_FIPS\":str,\n",
    "             \"COUNTY_FIPS\":str,\n",
    "             \"TRACT_FIPS\":str,\n",
    "             \"TOTAL_HOUSEHOLDS\":object,\n",
    "             \"TRIBAL_FIPS\":str,\n",
    "             \"JUD FTE PAYROLL FLAG\":str,\n",
    "             \"JUD PTE FLAG\":str,\n",
    "             \"JUD PT PAYROLL FLAG\":str,\n",
    "             \"JUD INDV UNIT ID\":str, # do we need these/ what are these?\n",
    "             \"PO FTE FLAG\":str,\n",
    "             \"PO FTE PAYROLL FLAG\":str,\n",
    "             \"PO INDV UNIT ID\":str,\n",
    "             \"RISK_RATNG\":str,\n",
    "             \"RESL_RATNG\":str,\n",
    "             \"ERQK_EXPT\":str, #i\"m not sure what these are\n",
    "             \"HWAV_EXPT\":str, #i\"m not sure what these are\n",
    "             \"HRCN_EXPT\":str, #i\"m not sure what these are\n",
    "             \"TRND_EXPT\":str, #i\"m not sure what these are\n",
    "             \"WFIR_EXPT\":str, #i\"m not sure what these are\n",
    "            }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee9fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2023 files\n",
    "county_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_county_500k.zip')\n",
    "aiannh_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_aiannh_500k.zip')\n",
    "division_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_division_500k.zip')\n",
    "region_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_region_500k.zip')\n",
    "state_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_state_500k.zip')\n",
    "tract_shp_2023 = gpd.read_file('/data/discover/Data/Geographic Data/2023/cb_2023_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f238aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2022 files\n",
    "county_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_county_500k.zip')\n",
    "aiannh_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_aiannh_500k.zip')\n",
    "division_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_division_500k.zip')\n",
    "region_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_region_500k.zip')\n",
    "state_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_state_500k.zip')\n",
    "tract_shp_2022 = gpd.read_file('/data/discover/Data/Geographic Data/2022/cb_2022_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab475fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2021 files\n",
    "county_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_county_500k.zip')\n",
    "aiannh_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_aiannh_500k.zip')\n",
    "division_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_division_500k.zip')\n",
    "region_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_region_500k.zip')\n",
    "state_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_state_500k.zip')\n",
    "tract_shp_2021 = gpd.read_file('/data/discover/Data/Geographic Data/2021/cb_2021_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4a5a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2020 files\n",
    "county_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_county_500k.zip')\n",
    "aiannh_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_aiannh_500k.zip')\n",
    "division_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_division_500k.zip')\n",
    "region_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_region_500k.zip')\n",
    "state_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_state_500k.zip')\n",
    "tract_shp_2020 = gpd.read_file('/data/discover/Data/Geographic Data/2020/cb_2020_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e358b6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2019 files\n",
    "county_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_county_500k.zip')\n",
    "aiannh_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_aiannh_500k.zip')\n",
    "division_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_division_500k.zip')\n",
    "region_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_region_500k.zip')\n",
    "state_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_state_500k.zip')\n",
    "tract_shp_2019 = gpd.read_file('/data/discover/Data/Geographic Data/2019/cb_2019_us_tract_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d149b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2018 files\n",
    "#no easy tract file\n",
    "county_shp_2018 = gpd.read_file('/data/discover/Data/Geographic Data/2018/cb_2018_us_county_500k.zip')\n",
    "aiannh_shp_2018 = gpd.read_file('/data/discover/Data/Geographic Data/2018/cb_2018_us_aiannh_500k.zip')\n",
    "division_shp_2018 = gpd.read_file('/data/discover/Data/Geographic Data/2018/cb_2018_us_division_500k.zip')\n",
    "region_shp_2018 = gpd.read_file('/data/discover/Data/Geographic Data/2018/cb_2018_us_region_500k.zip')\n",
    "state_shp_2018 = gpd.read_file('/data/discover/Data/Geographic Data/2018/cb_2018_us_state_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154e31f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2017 files\n",
    "#no easy tract file\n",
    "county_shp_2017 = gpd.read_file('/data/discover/Data/Geographic Data/2017/cb_2017_us_county_500k.zip')\n",
    "aiannh_shp_2017 = gpd.read_file('/data/discover/Data/Geographic Data/2017/cb_2017_us_aiannh_500k.zip')\n",
    "division_shp_2017 = gpd.read_file('/data/discover/Data/Geographic Data/2017/cb_2017_us_division_500k.zip')\n",
    "region_shp_2017 = gpd.read_file('/data/discover/Data/Geographic Data/2017/cb_2017_us_region_500k.zip')\n",
    "state_shp_2017 = gpd.read_file('/data/discover/Data/Geographic Data/2017/cb_2017_us_state_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eadb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2016 files\n",
    "#no easy tract file\n",
    "county_shp_2016 = gpd.read_file('/data/discover/Data/Geographic Data/2016/cb_2016_us_county_500k.zip')\n",
    "aiannh_shp_2016 = gpd.read_file('/data/discover/Data/Geographic Data/2016/cb_2016_us_aiannh_500k.zip')\n",
    "division_shp_2016 = gpd.read_file('/data/discover/Data/Geographic Data/2016/cb_2016_us_division_500k.zip')\n",
    "region_shp_2016 = gpd.read_file('/data/discover/Data/Geographic Data/2016/cb_2016_us_region_500k.zip')\n",
    "state_shp_2016 = gpd.read_file('/data/discover/Data/Geographic Data/2016/cb_2016_us_state_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faea66ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2015 files\n",
    "#no easy tract file\n",
    "county_shp_2015 = gpd.read_file('/data/discover/Data/Geographic Data/2015/cb_2015_us_county_500k.zip')\n",
    "aiannh_shp_2015 = gpd.read_file('/data/discover/Data/Geographic Data/2015/cb_2015_us_aiannh_500k.zip')\n",
    "division_shp_2015 = gpd.read_file('/data/discover/Data/Geographic Data/2015/cb_2015_us_division_500k.zip')\n",
    "region_shp_2015 = gpd.read_file('/data/discover/Data/Geographic Data/2015/cb_2015_us_region_500k.zip')\n",
    "state_shp_2015 = gpd.read_file('/data/discover/Data/Geographic Data/2015/cb_2015_us_state_500k.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3f407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to handle differences in data and shapefiles for AIANNH areas by R to end to match them.\n",
    "for shp in [aiannh_shp_2023,aiannh_shp_2022,aiannh_shp_2021,aiannh_shp_2020,aiannh_shp_2019,aiannh_shp_2018,aiannh_shp_2017,\n",
    "            aiannh_shp_2016,aiannh_shp_2015]:\n",
    "    shp['GEOID'] = shp['GEOID']+\"R\"\n",
    "    \n",
    "#To differentiate between division and region since the ids were exactly the same\n",
    "for shp in [division_shp_2023,division_shp_2022,division_shp_2021,division_shp_2020,division_shp_2019,division_shp_2018,division_shp_2017,\n",
    "            division_shp_2016,division_shp_2015]:\n",
    "    shp['GEOID'] = \"D\" + shp['GEOID']\n",
    "\n",
    "for shp in [region_shp_2023,region_shp_2022,region_shp_2021,region_shp_2020,region_shp_2019,region_shp_2018,region_shp_2017,\n",
    "            region_shp_2016,region_shp_2015]:\n",
    "    shp['GEOID'] = \"R\" + shp['GEOID']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85569892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#['2023','2022','2021','2020','2019','2018','2017','2016','2015']\n",
    "\n",
    "#Need to figure out how division and region are being handled\n",
    "\n",
    "for year in ['2015']:\n",
    "    #set this to run tracts, they take a while\n",
    "    run_tracts = True\n",
    "    print(year)\n",
    "    #create filepaths for outputs\n",
    "    out_path_aiannh = '/data/discover/Data/Geographic Data/'+year+'/cb_'+year+'_us_aiannh_500k.json'\n",
    "    out_path_county = '/data/discover/Data/Geographic Data/'+year+'/cb_'+year+'_us_county_500k.json'\n",
    "    out_path_division = '/data/discover/Data/Geographic Data/'+year+'/cb_'+year+'_us_division_500k.json'\n",
    "    out_path_region = '/data/discover/Data/Geographic Data/'+year+'/cb_'+year+'_us_region_500k.json'\n",
    "    out_path_state = '/data/discover/Data/Geographic Data/'+year+'/cb_'+year+'_us_state_500k.json'\n",
    "    \n",
    "    df_filter_by_year = df[df['YEAR'] == year].copy()\n",
    "    #Merge filtered table with each year shapfile\n",
    "    aiannh_key = 'aiannh_shp_{}'.format(year)\n",
    "    county_key = 'county_shp_{}'.format(year)\n",
    "    division_key = 'division_shp_{}'.format(year)\n",
    "    region_key = 'region_shp_{}'.format(year)\n",
    "    state_key = 'state_shp_{}'.format(year)\n",
    "\n",
    "    \n",
    "    aiannh_shp = locals()[aiannh_key].merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "    county_shp = locals()[county_key].merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "    division_shp = locals()[division_key].merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "    region_shp = locals()[region_key].merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "    state_shp = locals()[state_key].merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "    \n",
    "    write files as geojson for use in mapping\n",
    "    print(out_path_aiannh)\n",
    "    aiannh_shp.to_file(out_path_aiannh,driver=\"GeoJSON\")\n",
    "    print(out_path_county)\n",
    "    county_shp.to_file(out_path_county,driver=\"GeoJSON\")\n",
    "    print(out_path_division)\n",
    "    division_shp.to_file(out_path_division,driver=\"GeoJSON\")\n",
    "    print(out_path_region)\n",
    "    region_shp.to_file(out_path_region,driver=\"GeoJSON\")\n",
    "    print(out_path_state)\n",
    "    state_shp.to_file(out_path_state,driver=\"GeoJSON\")\n",
    "    #uses 2019 data for tracts before this year\n",
    "    if ((year in ['2022','2021','2020','2019']) and (run_tracts == True)):\n",
    "        tract_key = 'tract_shp_{}'.format(year)\n",
    "        states = list(locals()[tract_key]['STATEFP'].unique())\n",
    "        for state in states:\n",
    "            out_path_tract = '/data/discover/Data/Geographic Data/'+year+'/state_files_tract/cb_'+year+'_us_tract_500k_'+state+'.json'\n",
    "            print(out_path_tract)\n",
    "            state_tract_shape = locals()[tract_key][locals()[tract_key]['STATEFP'] == state]\n",
    "            tract_shp = state_tract_shape.merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "            tract_shp.to_file(out_path_tract,driver=\"GeoJSON\")\n",
    "    elif ((year in ['2018','2017','2016','2015']) and (run_tracts == True)):\n",
    "        tract_key = 'tract_shp_2019'\n",
    "        states = list(locals()[tract_key]['STATEFP'].unique())\n",
    "        for state in states:\n",
    "            out_path_tract = '/data/discover/Data/Geographic Data/'+year+'/state_files_tract/cb_'+year+'_us_tract_500k_'+state+'.json'\n",
    "            print(out_path_tract)\n",
    "            state_tract_shape = locals()[tract_key][locals()[tract_key]['STATEFP'] == state]\n",
    "            tract_shp = state_tract_shape.merge(df_filter_by_year,left_on='GEOID',right_on='GEO_ID')\n",
    "            tract_shp.to_file(out_path_tract,driver=\"GeoJSON\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

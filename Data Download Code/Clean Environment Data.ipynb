{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bf343af",
   "metadata": {},
   "source": [
    "# Clean Environment Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c51d5e8",
   "metadata": {},
   "source": [
    "I did not merge total green house gas emissions, total toxic chemicals released, or AQI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e7fd52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f83e1232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature\n",
    "temperature = pd.read_csv(\"/data/explore/dataExtracts/data/Quarterly temperature min & max 2015-2024.csv\", \n",
    "                     dtype={'year':str,'state_fips': str, 'census_region_code':str}, low_memory=False)\n",
    "\n",
    "#Keep only \"winter\" quarter\n",
    "temperature = temperature[temperature.quarter.str.contains(\"Winter\")]\n",
    "\n",
    "# Create GEO_ID\n",
    "temperature.loc[(temperature[\"census_region_code\"].isna()) \n",
    "                & (temperature[\"census_division_code\"].isna()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"GEO_ID\"] = 999\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull())\n",
    "                & (temperature[\"census_division_code\"].isna()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"GEO_ID\"] = temperature[\"census_region_code\"]\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull()) \n",
    "                & (temperature[\"census_division_code\"].notnull()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"GEO_ID\"] = temperature[\"census_division_code\"]\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull()) \n",
    "                & (temperature[\"census_division_code\"].notnull()) \n",
    "                & (temperature[\"state_fips\"].notnull()), \"GEO_ID\"] = temperature[\"state_fips\"]\n",
    "\n",
    "# Create area_type\n",
    "temperature.loc[(temperature[\"census_region_code\"].isna()) \n",
    "                & (temperature[\"census_division_code\"].isna()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"area_type\"] = \"national\"\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull())\n",
    "                & (temperature[\"census_division_code\"].isna()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"area_type\"] = \"region\"\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull()) \n",
    "                & (temperature[\"census_division_code\"].notnull()) \n",
    "                & (temperature[\"state_fips\"].isna()), \"area_type\"] = \"division\"\n",
    "\n",
    "temperature.loc[(temperature[\"census_region_code\"].notnull()) \n",
    "                & (temperature[\"census_division_code\"].notnull()) \n",
    "                & (temperature[\"state_fips\"].notnull()), \"area_type\"] = \"state\"\n",
    "\n",
    "#Drop extra variables\n",
    "temperature=temperature.drop(columns=[\"census_division_code\",\"census_region_code\",'Unnamed: 0',\n",
    "                                      'quarter','state_abbr','state_fips',\"state_name\"])\n",
    "\n",
    "#Fix GEO_ID formatting for merge\n",
    "temperature[\"GEO_ID\"] = temperature[\"GEO_ID\"].astype('float').astype('Int64').astype('str')\n",
    "temperature.loc[(temperature[\"area_type\"] == 'state') & (temperature[\"GEO_ID\"].str.len() == 1), \"GEO_ID\"] = '0' + temperature[\"GEO_ID\"]\n",
    "temperature.loc[(temperature[\"area_type\"] == 'national'), \"GEO_ID\"] = 'us'\n",
    "\n",
    "# Make all column names uppercase\n",
    "temperature.columns=map(str.upper, temperature.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26161cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly rainfall\n",
    "rain = pd.read_csv(\"/data/explore/dataExtracts/data/Yearly rainfall totals 2015-2024.csv\", \n",
    "                     dtype={'year':str}, low_memory=False)\n",
    "\n",
    "# Create GEO_ID\n",
    "rain.loc[(rain[\"census_region_code\"].isna()) \n",
    "                & (rain[\"census_division_code\"].isna()) \n",
    "                & (rain[\"state_fips\"].isna()), \"GEO_ID\"] = 999\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull())\n",
    "                & (rain[\"census_division_code\"].isna()) \n",
    "                & (rain[\"state_fips\"].isna()), \"GEO_ID\"] = rain[\"census_region_code\"]\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull()) \n",
    "                & (rain[\"census_division_code\"].notnull()) \n",
    "                & (rain[\"state_fips\"].isna()), \"GEO_ID\"] = rain[\"census_division_code\"]\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull()) \n",
    "                & (rain[\"census_division_code\"].notnull()) \n",
    "                & (rain[\"state_fips\"].notnull()), \"GEO_ID\"] = rain[\"state_fips\"]\n",
    "\n",
    "# Create area_type\n",
    "rain.loc[(rain[\"census_region_code\"].isna()) \n",
    "                & (rain[\"census_division_code\"].isna()) \n",
    "                & (rain[\"state_fips\"].isna()), \"area_type\"] = \"national\"\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull())\n",
    "                & (rain[\"census_division_code\"].isna()) \n",
    "                & (rain[\"state_fips\"].isna()), \"area_type\"] = \"region\"\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull()) \n",
    "                & (rain[\"census_division_code\"].notnull()) \n",
    "                & (rain[\"state_fips\"].isna()), \"area_type\"] = \"division\"\n",
    "\n",
    "rain.loc[(rain[\"census_region_code\"].notnull()) \n",
    "                & (rain[\"census_division_code\"].notnull()) \n",
    "                & (rain[\"state_fips\"].notnull()), \"area_type\"] = \"state\"\n",
    "\n",
    "#Drop extra variables\n",
    "rain=rain.drop(columns=[\"census_division_code\",\"census_region_code\",'Unnamed: 0',\n",
    "                                      'state_abbr','state_fips',\"state_name\"])\n",
    "\n",
    "#Fix GEO_ID formatting for merge\n",
    "rain[\"GEO_ID\"] = rain[\"GEO_ID\"].astype('float').astype('Int64').astype('str')\n",
    "rain.loc[(rain[\"area_type\"] == 'state') & (rain[\"GEO_ID\"].str.len() == 1), \"GEO_ID\"] = '0' + rain[\"GEO_ID\"]\n",
    "rain.loc[(rain[\"area_type\"] == 'national'), \"GEO_ID\"] = 'us'\n",
    "\n",
    "# Make all column names uppercase\n",
    "rain.columns=map(str.upper, rain.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fe1cce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Energy Consumption\n",
    "energy = pd.read_csv(\"/data/explore/dataExtracts/data/total_energy_consumption.csv\", \n",
    "                       dtype={'year':str,'state_fip': str}, low_memory=False)\n",
    "\n",
    "# Create GEO_ID\n",
    "energy.loc[(energy[\"area_type\"] == \"national\"), \"GEO_ID\"] = \"us\"\n",
    "energy.loc[(energy[\"area_type\"] == \"state\"), \"GEO_ID\"] = energy[\"state_fip\"]\n",
    "\n",
    "#Drop extra variables\n",
    "energy=energy.drop(columns=[\"state_abbreviation\",\"state_fip\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "energy.columns=map(str.upper, energy.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c92987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to assign fips codes off of abbreviation\n",
    "state_codes = {\n",
    "    'WA': '53', 'DE': '10', 'DC': '11', 'WI': '55', 'WV': '54', 'HI': '15',\n",
    "    'FL': '12', 'WY': '56', 'PR': '72', 'NJ': '34', 'NM': '35', 'TX': '48',\n",
    "    'LA': '22', 'NC': '37', 'ND': '38', 'NE': '31', 'TN': '47', 'NY': '36',\n",
    "    'PA': '42', 'AK': '02', 'NV': '32', 'NH': '33', 'VA': '51', 'CO': '08',\n",
    "    'CA': '06', 'AL': '01', 'AR': '05', 'VT': '50', 'IL': '17', 'GA': '13',\n",
    "    'IN': '18', 'IA': '19', 'MA': '25', 'AZ': '04', 'ID': '16', 'CT': '09',\n",
    "    'ME': '23', 'MD': '24', 'OK': '40', 'OH': '39', 'UT': '49', 'MO': '29',\n",
    "    'MN': '27', 'MI': '26', 'RI': '44', 'KS': '20', 'MT': '30', 'MS': '28',\n",
    "    'SC': '45', 'KY': '21', 'OR': '41', 'SD': '46', 'GU': '66', 'VI': '78'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7583841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cold Related Deaths\n",
    "cold = pd.read_csv(\"/data/explore/dataExtracts/data/Cold-Related Deaths 2015-2024.csv\", \n",
    "                       dtype={'year':str,'county_code':str, 'census_region_code':str, 'census_division_code':str},\n",
    "                   low_memory=False)\n",
    "\n",
    "#map fips codes onto states\n",
    "cold['state_fips'] = cold['state'].map(state_codes)\n",
    "\n",
    "# Clean year\n",
    "cold.loc[(cold[\"year\"] == \"2022 (provisional)\"), \"year\"] = \"2022\"\n",
    "cold.loc[(cold[\"year\"] == \"2023 (provisional)\"), \"year\"] = \"2023\"\n",
    "\n",
    "# Create GEO_ID\n",
    "cold.loc[(cold[\"census_region_code\"].isna()) \n",
    "                & (cold[\"census_division_code\"].isna()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"GEO_ID\"] = \"us\"\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull())\n",
    "                & (cold[\"census_division_code\"].isna()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"GEO_ID\"] = cold[\"census_region_code\"]\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"GEO_ID\"] = cold[\"census_division_code\"]\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].notnull())\n",
    "                & (cold[\"county_code\"].isna()), \"GEO_ID\"] = cold[\"state_fips\"]\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].notnull())\n",
    "                & (cold[\"county_code\"].notnull()), \"GEO_ID\"] = cold[\"county_code\"]\n",
    "\n",
    "# Create area_type\n",
    "cold.loc[(cold[\"census_region_code\"].isna()) \n",
    "                & (cold[\"census_division_code\"].isna()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"area_type\"] = \"national\"\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull())\n",
    "                & (cold[\"census_division_code\"].isna()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"area_type\"] = \"region\"\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].isna()) \n",
    "                & (cold[\"county_code\"].isna()), \"area_type\"] = \"division\"\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].notnull())\n",
    "                & (cold[\"county_code\"].isna()), \"area_type\"] = \"state\"\n",
    "\n",
    "cold.loc[(cold[\"census_region_code\"].notnull()) \n",
    "                & (cold[\"census_division_code\"].notnull()) \n",
    "                & (cold[\"state\"].notnull())\n",
    "                & (cold[\"county_code\"].notnull()), \"area_type\"] = \"county\"\n",
    "\n",
    "#rename death variable\n",
    "cold.rename(columns={'deaths':'cold_related_deaths'}, inplace=True)\n",
    "\n",
    "#Drop extra variables\n",
    "cold=cold.drop(columns=[\"census_division_code\",\"census_region_code\",'Unnamed: 0',\n",
    "                                      'state','county_code',\"county\", \"population\",'state_fips'])\n",
    "\n",
    "#drop duplicates\n",
    "cold = cold.drop_duplicates()\n",
    "\n",
    "# Make all column names uppercase\n",
    "cold.columns=map(str.upper, cold.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0bac56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heat Related Deaths\n",
    "heat = pd.read_csv(\"/data/explore/dataExtracts/data/Heat-Related Deaths 2015-2024.csv\", \n",
    "                       dtype={'year':str,'county_code': str, 'census_region_code':str, 'census_division_code':str},\n",
    "                   low_memory=False)\n",
    "\n",
    "#map fips codes onto states\n",
    "heat['state_fips'] = heat['state'].map(state_codes)\n",
    "\n",
    "# Clean year\n",
    "heat.loc[(heat[\"year\"] == \"2022 (provisional)\"), \"year\"] = \"2022\"\n",
    "heat.loc[(heat[\"year\"] == \"2023 (provisional)\"), \"year\"] = \"2023\"\n",
    "heat.loc[(heat[\"year\"] == \"2024 (provisional and partial)\"), \"year\"] = \"2024\"\n",
    "\n",
    "# Create GEO_ID\n",
    "heat.loc[(heat[\"census_region_code\"].isna()) \n",
    "                & (heat[\"census_division_code\"].isna()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"GEO_ID\"] = \"us\"\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull())\n",
    "                & (heat[\"census_division_code\"].isna()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"GEO_ID\"] = heat[\"census_region_code\"]\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"GEO_ID\"] = heat[\"census_division_code\"]\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].notnull())\n",
    "                & (heat[\"county_code\"].isna()), \"GEO_ID\"] = heat[\"state_fips\"]\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].notnull())\n",
    "                & (heat[\"county_code\"].notnull()), \"GEO_ID\"] = heat[\"county_code\"]\n",
    "\n",
    "# Create area_type\n",
    "heat.loc[(heat[\"census_region_code\"].isna()) \n",
    "                & (heat[\"census_division_code\"].isna()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"area_type\"] = \"national\"\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull())\n",
    "                & (heat[\"census_division_code\"].isna()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"area_type\"] = \"region\"\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].isna()) \n",
    "                & (heat[\"county_code\"].isna()), \"area_type\"] = \"division\"\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].notnull())\n",
    "                & (heat[\"county_code\"].isna()), \"area_type\"] = \"state\"\n",
    "\n",
    "heat.loc[(heat[\"census_region_code\"].notnull()) \n",
    "                & (heat[\"census_division_code\"].notnull()) \n",
    "                & (heat[\"state\"].notnull())\n",
    "                & (heat[\"county_code\"].notnull()), \"area_type\"] = \"county\"\n",
    "\n",
    "#rename death variable\n",
    "heat.rename(columns={'deaths':'heat_related_deaths'}, inplace=True)\n",
    "\n",
    "#Drop extra variables\n",
    "heat=heat.drop(columns=[\"census_division_code\",\"census_region_code\",'Unnamed: 0',\n",
    "                                      'state','county_code',\"county\", \"population\", 'state_fips'])\n",
    "\n",
    "#drop duplicates\n",
    "heat = heat.drop_duplicates()\n",
    "\n",
    "# Make all column names uppercase\n",
    "heat.columns=map(str.upper, heat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2f8d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asthma Rate\n",
    "asthma = pd.read_excel(\"/data/explore/dataExtracts/data/asthma_rates.xlsx\", sheet_name='Indicator', \n",
    "                     dtype={'Year':str,'StateFIPS':str, 'CountyFIPS':str})\n",
    "\n",
    "#asthma = asthma.astype({'StateFIPS': str, 'CountyFIPS': str})\n",
    "\n",
    "#Add missing 0s for FIPS codes\n",
    "asthma.loc[(asthma['CountyFIPS'].str.len() == 4), 'CountyFIPS'] = '0' + asthma['CountyFIPS']\n",
    "asthma.loc[(asthma['StateFIPS'].str.len() == 1), 'StateFIPS'] = '0' + asthma['StateFIPS']\n",
    "\n",
    "# Create GEO_ID\n",
    "asthma.loc[(asthma[\"area_type\"] == \"national\"), \"GEO_ID\"] = \"us\"\n",
    "asthma.loc[(asthma[\"area_type\"] == \"state\"), \"GEO_ID\"] = asthma[\"StateFIPS\"]\n",
    "asthma.loc[(asthma[\"area_type\"] == \"county\"), \"GEO_ID\"] = asthma[\"CountyFIPS\"]\n",
    "\n",
    "#Drop extra variables\n",
    "asthma=asthma.drop(columns=[\"StateFIPS\",\"CountyFIPS\",\"geo_name\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "asthma.columns=map(str.upper, asthma.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12e07e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mean Nitrate Concentration\n",
    "nitrate = pd.read_excel(\"/data/explore/dataExtracts/data/mean_nitrate_con.xlsx\", sheet_name='Indicator', \n",
    "                     dtype={'Year':str,'StateFIPS':str, 'CountyFIPS':str})\n",
    "\n",
    "#Add missing 0s for FIPS codes\n",
    "nitrate.loc[(nitrate['CountyFIPS'].str.len() == 4), 'CountyFIPS'] = '0' + nitrate['CountyFIPS']\n",
    "nitrate.loc[(nitrate['StateFIPS'].str.len() == 1), 'StateFIPS'] = '0' + nitrate['StateFIPS']\n",
    "\n",
    "# Create GEO_ID\n",
    "nitrate.loc[(nitrate[\"area_type\"] == \"national\"), \"GEO_ID\"] = \"us\"\n",
    "nitrate.loc[(nitrate[\"area_type\"] == \"state\"), \"GEO_ID\"] = nitrate[\"StateFIPS\"]\n",
    "nitrate.loc[(nitrate[\"area_type\"] == \"county\"), \"GEO_ID\"] = nitrate[\"CountyFIPS\"]\n",
    "\n",
    "#Drop extra variables\n",
    "nitrate=nitrate.drop(columns=[\"StateFIPS\",\"CountyFIPS\",\"geo_name\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "nitrate.columns=map(str.upper, nitrate.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f65cc06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge\n",
    "environment = pd.merge(temperature, rain, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer').merge(energy, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer').merge(cold, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer').merge(heat, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer').merge(asthma, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer').merge(nitrate, on=['GEO_ID','YEAR','AREA_TYPE'],\n",
    "                     how='outer')\n",
    "\n",
    "#Account for county fips changes\n",
    "environment.loc[(environment[\"GEO_ID\"] == '02270') & (environment[\"YEAR\"] != '2015'), \"GEO_ID\"] = '02158'\n",
    "environment.loc[(environment[\"GEO_ID\"] == '46113') & (environment[\"YEAR\"] != '2015'), \"GEO_ID\"] = '46102'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10925b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add Geo_names\n",
    "geo = pd.read_csv(\"/data/discover/Data/General/general_measures.csv\", \n",
    "                     dtype={'year':str,'state_fips': object,'county_fips':object,\n",
    "                            'tract_fips':object,'GEO_ID':str,'area_type':str,'Geo_name':str}, low_memory=False)\n",
    "\n",
    "#Drop MOE variables\n",
    "geo=geo[['state_fips','county_fips','GEO_ID','area_type','Geo_name']]\n",
    "#drop duplicates\n",
    "geo = geo.drop_duplicates()\n",
    "# Make all column names uppercase\n",
    "geo.columns=map(str.upper, geo.columns)\n",
    "\n",
    "#Merge\n",
    "environment_merge = pd.merge(environment, geo, on=['GEO_ID','AREA_TYPE'],\n",
    "                     how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c55c020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in folder\n",
    "environment_merge.to_csv(\"/data/discover/Data/Final Data/Environment and Natural Resources/environment.csv\", \n",
    "                         header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a425f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A significant number of county fips codes are missing for AQI so did not include\n",
    "\n",
    "# AQI\n",
    "aqi = pd.read_excel(\"/data/explore/dataExtracts/data/AQI.xlsx\", sheet_name='Indicator', \n",
    "                     dtype={'Year':str,'StateFIPS':str, 'CountyFIPS':str})\n",
    "\n",
    "#Keep only US geographies\n",
    "aqi = aqi[aqi.StateFIPS.notnull()]\n",
    "aqi = aqi[~aqi.StateFIPS.str.contains(\"78\")]\n",
    "\n",
    "#Add missing 0s for FIPS codes\n",
    "aqi.loc[(aqi['CountyFIPS'].str.len() == 4), 'CountyFIPS'] = '0' + aqi['CountyFIPS']\n",
    "aqi.loc[(aqi['StateFIPS'].str.len() == 1), 'StateFIPS'] = '0' + aqi['StateFIPS']\n",
    "\n",
    "# Create GEO_ID\n",
    "aqi.loc[(aqi[\"area_type\"] == \"national\"), \"GEO_ID\"] = \"us\"\n",
    "aqi.loc[(aqi[\"area_type\"] == \"state\"), \"GEO_ID\"] = aqi[\"StateFIPS\"]\n",
    "aqi.loc[(aqi[\"area_type\"] == \"county\"), \"GEO_ID\"] = aqi[\"StateFIPS\"] + aqi[\"CountyFIPS\"]\n",
    "\n",
    "#Drop extra variables\n",
    "aqi=aqi.drop(columns=[\"StateFIPS\",\"CountyFIPS\", \"geo_name\"])\n",
    "\n",
    "# Make all column names uppercase\n",
    "aqi.columns=map(str.upper, aqi.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb748d9d",
   "metadata": {},
   "source": [
    "# Downloading Census Data for Transportation, Infrastructure, and Housing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbaa648",
   "metadata": {},
   "source": [
    "I wanted to use the package \"censusdis\" and/or the package \"census\" to download census data \n",
    "using the API, but we don't have access to it in EDL. I asked Brock Webb about it.\n",
    "\n",
    "Brock said, \"That can be done via a remedy request to install the package. \n",
    "The bad thing is... even if you do that, I didn't think EDL had open Internet access, \n",
    "so it doesn't work. That was a struggle I had with the python packages. They made it \n",
    "very easy to get the data as demonstrated today. However, I couldn't do that, so I \n",
    "had to get it manually from data.census.gov and figure out how to get what I wanted \n",
    "into a table so I could import the file. \"\n",
    "\n",
    "So instead of using a package, I'm using the following code.\n",
    "\n",
    "If there is time, these are the things I would add to the code:\n",
    "\n",
    "1. Full distributions for home value and time of departure\n",
    "2. Where 1-year data are available, use 1-year instead of 5-year (applies to county and tribal areas)\n",
    "3. Add block group data\n",
    "4. Add more \"loops\" and \"if-else\" code so I don't need as many functions\n",
    "5. Make adjustments for geo changes over time\n",
    "6. Make adjustments for Puerto Rico\n",
    "7. Make adjustments for tribal area name\n",
    "8. QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faba067f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Create a blank dataframe for appending data\n",
    "house = pd.DataFrame()\n",
    "internet = pd.DataFrame()\n",
    "\n",
    "# year loop for different geos\n",
    "vin = [\"2022\",\"2021\",\"2019\",\"2018\",\"2017\",\"2016\",\"2015\"]\n",
    "vina = [\"2022\",\"2021\",\"2020\",\"2019\",\"2018\",\"2017\",\"2016\",\"2015\"]\n",
    "vinb = [\"2022\",\"2021\",\"2020\",\"2019\"]\n",
    "vinc = [\"2018\",\"2017\",\"2016\",\"2015\"]\n",
    "vind = [\"2022\",\"2021\",\"2019\",\"2018\",\"2017\"]\n",
    "vine = [\"2018\",\"2017\"]\n",
    "\n",
    "# variables for data profiles\n",
    "get_vars_dp = ([\"NAME\", \"DP04_0001E\", \"DP04_0001M\", #total HUs\n",
    "                \"DP04_0089E\", \"DP04_0089M\", #median home value\n",
    "                \"DP04_0134E\", \"DP04_0134M\", #rent\n",
    "                \"DP03_0019PE\", \"DP03_0019PM\", #drove alone\n",
    "                \"DP03_0020PE\", \"DP03_0020PM\", #carpooled\n",
    "                \"DP03_0021PE\", \"DP03_0021PM\", #public transport\n",
    "                \"DP03_0022PE\", \"DP03_0022PM\", #walked\n",
    "                \"DP03_0025E\", \"DP03_0025E\", #average commute\n",
    "                \"DP04_0077PE\", \"DP04_0077PM\", #1 or less\n",
    "                \"DP04_0078PE\", \"DP04_0078PM\", #1 to 1.5\n",
    "                \"DP04_0079PE\", \"DP04_0079PM\", #1.5\n",
    "                \"DP04_0063PE\", \"DP04_0063PM\", #utility gas\n",
    "                \"DP04_0064PE\", \"DP04_0064PM\", #tank gas\n",
    "                \"DP04_0065PE\", \"DP04_0065PM\", #electricity\n",
    "                \"DP04_0066PE\", \"DP04_0066PM\", #kerosene\n",
    "                \"DP04_0069PE\", \"DP04_0069PM\", #solar\n",
    "                \"DP04_0071PE\", \"DP04_0071PM\", #no fuel\n",
    "                \"DP03_0034E\", \"DP03_0034M\", #construction\n",
    "                \"DP04_0003PE\", \"DP04_0003PM\", #vacancy\n",
    "                \"GEO_ID\"])\n",
    "\n",
    "# variable names for subject tables\n",
    "get_vars_sub = [\"NAME\", \"S2801_C02_017E\", \"S2801_C02_017M\", #broadband\n",
    "                \"S2801_C02_015E\", \"S2801_C02_015M\", #cellular\n",
    "                \"S2801_C02_018E\", \"S2801_C02_018E\", #satellite\n",
    "                \"GEO_ID\"]\n",
    "    \n",
    "# column names for data profiles\n",
    "col_names_dp = ['Geo_name', 'Total_housing_units', 'Total_housing_units_moe',\n",
    "                 'Median_home_value', 'Median_home_value_moe',\n",
    "                 'Median_gross_rent', 'Median_gross_rent_moe',\n",
    "                 \"Percent_drove_alone\", \"Percent_drove_alone_moe\",\n",
    "                 \"Percent_carpooled\", \"Percent_carpooled_moe\",\n",
    "                 \"Percent_public_transportation\", \"Percent_public_transportation_moe\",\n",
    "                 \"Percent_walked\", \"Percent_walked_moe\",\n",
    "                 \"Average_commute_time\", \"Average_commute_time_moe\",\n",
    "                 \"Percent_with_1.00_occupent_or_less\", \"Percent_with_1.00_occupent_or_less_moe\",\n",
    "                 \"Percent_with_1.01_to_1.50_occupents\", \"Percent_with_1.01_to_1.50_occupents_moe\",\n",
    "                 \"Percent_with_1.51_or_more_occupents\", \"Percent_with_1.51_or_more_occupents_moe\",\n",
    "                 \"Percent_with_utility_gas\", \"Percent_with_utility_gas_moe\",\n",
    "                 \"Percent_with_bottled_tank_lp_gas\", \"Percent_with_bottled_tank_lp_gas_moe\",\n",
    "                 \"Percent_with_electricity\", \"Percent_with_electricity_moe\",\n",
    "                 \"Percent_with_oil_kerosene_etc\", \"Percent_with_oil_kerosene_etc_moe\",\n",
    "                 \"Percent_with_solar\", \"Percent_with_solar_moe\",\n",
    "                 \"Percent_with_no_fuel\", \"Percent_with_no_fuel_moe\",\n",
    "                 \"Number_employed_construction\", \"Number_employed_construction_moe\",\n",
    "                 \"Percent_vacant\", \"Percent_vacant_moe\"]\n",
    "\n",
    "# column names for subject tables\n",
    "col_names_sub = ['Geo_name', 'Percent_with_broadband_cable_fiber_esl', 'Percent_with_broadband_cable_fiber_esl_moe',\n",
    "                 'Percent_with_cellular_data_plan', 'Percent_with_cellular_data_plan_moe',\n",
    "                 'Percent_with_satellite_internet', 'Percent_with_satellite_internet_moe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf9082b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for the nation for data profiles\n",
    "\n",
    "def api_us(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"us:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['GEO_ID',\"fips\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"national\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = \"us\"\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b34f3d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years except 2020\n",
    "for x in vin:\n",
    "    api_us(year=x, dataset = \"acs/acs1/profile?\")\n",
    "\n",
    "#run for 2020 (could make vin loop a dictionary and not have to run this part...)\n",
    "api_us(year=\"2020\", dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf48f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for region and division for data profiles\n",
    "\n",
    "def api_rd(year, dataset, geo_for, area_type, geo_id):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = geo_for\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['GEO_ID',\"fips\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = area_type\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df[geo_id] \n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab6099b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#region\n",
    "#run for all years except 2020\n",
    "for x in vin:\n",
    "    api_rd(year=x, dataset = \"acs/acs1/profile?\", geo_for = \"region:*\", area_type=\"region\", geo_id = [\"fips\"])\n",
    "\n",
    "#run for 2020 (could make vin loop a dictionary and not have to run this part...)\n",
    "api_rd(year=\"2020\", dataset = \"acs/acs5/profile?\", geo_for = \"region:*\", area_type=\"region\", geo_id = [\"fips\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce7c8a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#division\n",
    "#run for all years except 2020\n",
    "for x in vin:\n",
    "    api_rd(year=x, dataset = \"acs/acs1/profile?\", geo_for = \"division:*\", area_type=\"division\", geo_id = [\"fips\"])\n",
    "\n",
    "#run for 2020 (could make vin loop a dictionary and not have to run this part...)\n",
    "api_rd(year=\"2020\", dataset = \"acs/acs5/profile?\", geo_for = \"division:*\", area_type=\"division\", geo_id = [\"fips\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2dbee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for state for data profiles\n",
    "\n",
    "def api_st(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"state:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + [\"fips\",'GEO_ID']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"state\"\n",
    "    df[\"state_fips\"] = df['fips'].str[9:11]\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:11]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9ecb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years except 2020\n",
    "for x in vin:\n",
    "    api_st(year=x, dataset = \"acs/acs1/profile?\")\n",
    "\n",
    "#run for 2020 (could make vin loop a dictionary and not have to run this part...)\n",
    "api_st(year=\"2020\", dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aea2346",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for county for data profiles\n",
    "\n",
    "def api_cty(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"county:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['GEO_ID',\"state_fips\",\"county_fips\"]    \n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"county\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['GEO_ID'].str[9:14]\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfe446cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vina:\n",
    "    api_cty(year=x, dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f11e0e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tribal areas for data profiles (2022 - 2019)\n",
    "\n",
    "def api_aian(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"american indian area/alaska native area (reservation or statistical entity only):*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['fips','GEO_ID']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tribal_area\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:14]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e8b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for years (2022 - 2019)\n",
    "for x in vinb:\n",
    "    api_aian(year=x, dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41da8503",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tribal areas for data profiles (2015 - 2018)\n",
    "\n",
    "def api_aian(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"american indian area/alaska native area (reservation or statistical entity only):*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['fips','GEO_ID','R']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tribal_area\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:14]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "    df.drop('R', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7233e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for years (2015 - 2018)\n",
    "for x in vinc:\n",
    "    api_aian(year=x, dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78fd6b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tracts for data profiles\n",
    "\n",
    "def api_tract(year, dataset):\n",
    "    global house\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_dp)\n",
    "    predicates[\"for\"] = \"tract:*\"\n",
    "    predicates[\"in\"] = \"state:01,02,04,05,06,08,09,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,50,51,53,54,55,56,72\"\n",
    "\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_dp + ['GEO_ID','state_fips', 'county_fips', 'tract_fips']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tract\"\n",
    "    df[\"GEO_ID\"] = df['GEO_ID'].str[9:20]\n",
    "   \n",
    "    #append data\n",
    "    house = pd.concat([house,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "930e4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vina:\n",
    "    api_tract(year=x, dataset = \"acs/acs5/profile?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b220f640",
   "metadata": {},
   "source": [
    "The following functions are for internet data (only back until 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "66cfd676",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for the nation for internet\n",
    "\n",
    "def api_us(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"us:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + ['GEO_ID',\"fips\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"national\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = \"us\"\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "feb88eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vind:\n",
    "    api_us(year=x, dataset = \"acs/acs1/subject?\")\n",
    "    \n",
    "api_us(year=\"2020\", dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7daa8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for region and division for internet\n",
    "\n",
    "def api_rd(year, dataset, geo_for, area_type, geo_id):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = geo_for\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + ['GEO_ID',\"fips\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = area_type\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df[geo_id]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cabdef5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#region\n",
    "#run for all years\n",
    "for x in vind:\n",
    "    api_rd(year=x, dataset = \"acs/acs1/subject?\", geo_for = \"region:*\", area_type=\"region\", geo_id = [\"fips\"])\n",
    "    \n",
    "api_rd(year=\"2020\", dataset = \"acs/acs5/subject?\", geo_for = \"region:*\", area_type=\"region\", geo_id = [\"fips\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1312bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#division\n",
    "#run for all years\n",
    "for x in vind:\n",
    "    api_rd(year=x, dataset = \"acs/acs1/subject?\", geo_for = \"division:*\", area_type=\"division\", geo_id = [\"fips\"])\n",
    "    \n",
    "api_rd(year=\"2020\", dataset = \"acs/acs5/subject?\", geo_for = \"division:*\", area_type=\"division\", geo_id = [\"fips\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f817774",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for the state for internet\n",
    "\n",
    "def api_st(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"state:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + [\"fips\", 'GEO_ID']    \n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"state\"\n",
    "    df[\"state_fips\"] = df['fips'].str[9:11]\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:11]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7c5974f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vind:\n",
    "    api_st(year=x, dataset = \"acs/acs1/subject?\")\n",
    "    \n",
    "api_st(year=\"2020\", dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d3ed47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for counties for internet\n",
    "\n",
    "def api_cty(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"county:*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + ['GEO_ID',\"state_fips\",\"county_fips\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"county\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['GEO_ID'].str[9:14]\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f8ea491",
   "metadata": {},
   "outputs": [],
   "source": [
    "vinf = [\"2022\",\"2021\",\"2020\",\"2019\",\"2018\",\"2017\"]\n",
    "\n",
    "#run for all years\n",
    "for x in vinf:\n",
    "    api_cty(year=x, dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "108172c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tribal areas for internet (2019 - 2020)\n",
    "\n",
    "def api_aian(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"american indian area/alaska native area (reservation or statistical entity only):*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + [\"fips\",'GEO_ID']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tribal_area\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:14]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a38cdbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vinb:\n",
    "    api_aian(year=x, dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3309fb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tribal areas for internet (2017 - 2018)\n",
    "\n",
    "def api_aian(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"american indian area/alaska native area (reservation or statistical entity only):*\"\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + [\"fips\",'GEO_ID',\"R\"]\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tribal_area\"\n",
    "    df[\"state_fips\"] = \"\"\n",
    "    df[\"county_fips\"] = \"\"\n",
    "    df[\"tract_fips\"] = \"\"\n",
    "    df[\"GEO_ID\"] = df['fips'].str[9:14]\n",
    "    df.drop('fips', axis=1, inplace=True)\n",
    "    df.drop('R', axis=1, inplace=True)\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c70c8290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vine:\n",
    "    api_aian(year=x, dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6550ebdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the function for tracts\n",
    "\n",
    "def api_tract(year, dataset):\n",
    "    global internet\n",
    "\n",
    "    # Build base URL\n",
    "    HOST = \"https://api.census.gov/data\"\n",
    "    base_url = \"/\".join([HOST, year, dataset])\n",
    "\n",
    "    # Specify Census variables and other predicates\n",
    "    predicates = {}\n",
    "    predicates[\"get\"] = \",\".join(get_vars_sub)\n",
    "    predicates[\"for\"] = \"tract:*\"\n",
    "    predicates[\"in\"] = \"state:01,02,04,05,06,08,09,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,44,45,46,47,48,49,50,51,53,54,55,56,72\"\n",
    "\n",
    "\n",
    "    # Execute the request, examine text of response object\n",
    "    r = requests.get(base_url, params=predicates)\n",
    "\n",
    "    # Construct the DataFrame\n",
    "    col_names = col_names_sub + ['GEO_ID','state_fips', 'county_fips', 'tract_fips']\n",
    "    df = pd.DataFrame(columns = col_names, data = r.json()[1:])\n",
    "                \n",
    "    # Create additional variables for file\n",
    "    df[\"year\"] = year\n",
    "    df[\"area_type\"] = \"tract\"\n",
    "    df[\"GEO_ID\"] = df['GEO_ID'].str[9:20]\n",
    "   \n",
    "    #append data\n",
    "    internet = pd.concat([internet,df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7fe87a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run for all years\n",
    "for x in vinf:\n",
    "    api_tract(year=x, dataset = \"acs/acs5/subject?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4d82f0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge housing and internet data\n",
    "\n",
    "Housing_trans_infra_measures = house.merge(internet, how='left', left_on=['Geo_name','GEO_ID','year','area_type','state_fips','county_fips','tract_fips'],\n",
    "                                             right_on=['Geo_name','GEO_ID','year','area_type','state_fips','county_fips','tract_fips'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "084b1e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CSV\n",
    "Housing_trans_infra_measures.to_csv(\"/data/discover/Data/Infrastructure and Transportation/Housing_trans_infra_measures.csv\", header=True, index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
